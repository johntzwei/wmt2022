{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845282ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a297c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBLIC_RELEASE_PATH = \"C:/Users/t-johnnywei/Documents/GitHub/ToShipOrNotToShip\\public_release\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3525e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(use_cache=True):\n",
    "    cache_filename = \"data.pickle\"\n",
    "    data = defaultdict(dict)\n",
    "    if use_cache and os.path.isfile(cache_filename):\n",
    "        with open(cache_filename, 'rb') as handle:\n",
    "            data = pickle.load(handle)\n",
    "    else:\n",
    "        _, campaigns_list, _ = next(os.walk(PUBLIC_RELEASE_PATH))\n",
    "        counter = 1\n",
    "        for campaign in campaigns_list:\n",
    "            if campaign not in data:\n",
    "                data[campaign] = defaultdict(dict)\n",
    "            for _, _, systems_list in os.walk(f\"{PUBLIC_RELEASE_PATH}/{campaign}\"):\n",
    "                for system in systems_list:\n",
    "                    if system not in data[campaign]:\n",
    "                        data[campaign][system] = defaultdict(dict)\n",
    "                    print(f\"Loading {counter}/{len(campaigns_list)} campaign\")\n",
    "                    xls = pd.ExcelFile(f\"{PUBLIC_RELEASE_PATH}/{campaign}/{system}\")\n",
    "                    for datatype in xls.sheet_names:\n",
    "                        if datatype in [\"hum_annotations\",\n",
    "                                        \"full_test\"]:\n",
    "                            data[campaign][system][datatype] = pd.read_excel(\n",
    "                                xls, datatype)\n",
    "                        else:\n",
    "                            df = pd.read_excel(xls, datatype)\n",
    "                            # transform to dictionary\n",
    "                            df_dict = df.set_index(\"Unnamed: 0\").transpose()\n",
    "                            df_dict = df_dict.iloc[0].to_dict()\n",
    "                            data[campaign][system][datatype] = df_dict\n",
    "                counter += 1\n",
    "\n",
    "        # save the cache data\n",
    "        if use_cache:\n",
    "            with open(cache_filename, 'wb') as handle:\n",
    "                pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(\"Annotated data loaded\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd0fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated data loaded\n"
     ]
    }
   ],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda9659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs():\n",
    "    for (k, v) in data.items():\n",
    "        for i, j in itertools.combinations(v, 2):\n",
    "            yield (v[i]['hum_annotations'], v[j]['hum_annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5a4ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ENU', 'FRA'),\n",
       " ('ENU', 'DEU'),\n",
       " ('FRA', 'ENU'),\n",
       " ('DEU', 'ENU'),\n",
       " ('JPN', 'ENU'),\n",
       " ('ENU', 'JPN'),\n",
       " ('ITA', 'ENU'),\n",
       " ('CHS', 'ENU'),\n",
       " ('ENU', 'PTB'),\n",
       " ('ENU', 'SVE')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get language pairs\n",
    "lps = []\n",
    "for i, j in pairs():\n",
    "    source, target = list(i['Source'].unique())[0], list(i['Target'].unique())[0]\n",
    "    lps.append((source, target))\n",
    "\n",
    "st = []\n",
    "for (s, t), c in Counter(lps).most_common(10):\n",
    "    st.append((s,t))\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d0b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mde(sorted_results):\n",
    "    p_test = 0.05\n",
    "    threshold = 0.95\n",
    "    sig, insig = 0, 0\n",
    "    last_diff = 0\n",
    "    for diff, pvalue in sorted_results:\n",
    "        if pvalue < 0.05:\n",
    "            sig += 1\n",
    "        else:\n",
    "            insig += 1\n",
    "\n",
    "        if sig / (sig + insig) < threshold:\n",
    "            return last_diff, sig, insig\n",
    "        last_diff = diff\n",
    "        \n",
    "    # no mde found\n",
    "    return None, sig, insig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9262c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENU $\\rightarrow$ FRA\t30 / 153\t3.8\t1.2\n",
      "ENU $\\rightarrow$ DEU\t19 / 151\t3.5\t0.7\n",
      "FRA $\\rightarrow$ ENU\t3 / 140\t2.4\t0.6\n",
      "DEU $\\rightarrow$ ENU\t27 / 130\t1.9\t0.6\n",
      "JPN $\\rightarrow$ ENU\t78 / 127\t2.9\t3.2\n",
      "ENU $\\rightarrow$ JPN\t40 / 94\t3.8\t1.8\n",
      "ITA $\\rightarrow$ ENU\t2 / 81\t2.8\t0.5\n",
      "CHS $\\rightarrow$ ENU\t30 / 78\t2.6\t1.5\n",
      "ENU $\\rightarrow$ PTB\t28 / 74\t1.0\t0.6\n",
      "ENU $\\rightarrow$ SVE\t31 / 73\t4.4\t1.4\n"
     ]
    }
   ],
   "source": [
    "for source, target in st:\n",
    "    records = []\n",
    "    records.append('%s $\\\\rightarrow$ %s' % (source, target))\n",
    "    \n",
    "    lp_pairs = []\n",
    "    for i, j in pairs():\n",
    "        s = i['Source'].unique()\n",
    "        t = i['Target'].unique()\n",
    "\n",
    "        if source == s and target == t:\n",
    "            lp_pairs.append((i, j))\n",
    "    \n",
    "    results = []\n",
    "    for df1, df2 in lp_pairs:\n",
    "        diff = np.abs(df1['Score'].mean() - df2['Score'].mean())\n",
    "        s, pvalue = scipy.stats.mannwhitneyu(df1['Score'], df2['Score'])\n",
    "        results.append((diff, pvalue))\n",
    "    results = np.array(results)\n",
    "    records.append('%d / %d' % (np.sum(results[:, 1] < 0.05), len(results)))\n",
    "    \n",
    "    order = (-results[:, 0]).argsort()\n",
    "    sorted_results = results[order]\n",
    "    obs_mde, sig, insig = mde(sorted_results)\n",
    "    records.append('%.1f' % obs_mde)\n",
    "    \n",
    "    # get 25th percentile\n",
    "    q_diff = sorted_results[int(len(sorted_results) * 0.5), 0]\n",
    "    records.append('%.1f' % q_diff)\n",
    "    \n",
    "    print('\\t'.join([str(i) for i in records ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b852389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENU $\\rightarrow$ FRA\t90.294452\t18.246645\n",
      "ENU $\\rightarrow$ DEU\t91.991749\t14.313352\n",
      "FRA $\\rightarrow$ ENU\t92.475884\t13.612182\n",
      "DEU $\\rightarrow$ ENU\t91.650683\t14.927010\n",
      "JPN $\\rightarrow$ ENU\t70.862999\t22.906902\n",
      "ENU $\\rightarrow$ JPN\t74.447273\t21.982557\n",
      "ITA $\\rightarrow$ ENU\t88.314317\t13.256383\n",
      "CHS $\\rightarrow$ ENU\t79.394058\t15.501552\n",
      "ENU $\\rightarrow$ PTB\t92.392836\t11.026530\n",
      "ENU $\\rightarrow$ SVE\t85.327524\t19.834718\n"
     ]
    }
   ],
   "source": [
    "for source, target in st:\n",
    "    records = []\n",
    "    records.append('%s $\\\\rightarrow$ %s' % (source, target))\n",
    "    \n",
    "    lp_pairs = []\n",
    "    for i, j in pairs():\n",
    "        s = i['Source'].unique()\n",
    "        t = i['Target'].unique()\n",
    "\n",
    "        if source == s and target == t:\n",
    "            lp_pairs.append((i, j))\n",
    "    \n",
    "    results = []\n",
    "    for df1, df2 in lp_pairs:\n",
    "        results.append(df1['Score'].mean())\n",
    "        results.append(df2['Score'].mean())\n",
    "    records.append('%f' % np.mean(results))\n",
    "    \n",
    "    results = []\n",
    "    for df1, df2 in lp_pairs:\n",
    "        results.append(df1['Score'].std())\n",
    "        results.append(df2['Score'].std())\n",
    "    records.append('%f' % np.mean(results))\n",
    "    \n",
    "    print('\\t'.join([str(i) for i in records ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b31f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
